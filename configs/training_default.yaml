model: configs/model_150m.yaml
tokenizer_path: tokenizer/codeforge.json

data:
  sources:
    - "bigcode/the-stack-v2-train-smol-ids"
  max_seq_len: 2048
  languages:
    - python
    - javascript
    - java
    - cpp
    - go
    - rust
    - typescript
  fim_rate: 0.5

training:
  batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 3.0e-4
  min_lr_ratio: 0.1
  warmup_steps: 1000
  max_steps: 100000
  weight_decay: 0.1
  max_grad_norm: 1.0
  precision: bf16
  checkpoint_dir: checkpoints
  checkpoint_every: 5000
  eval_every: 1000
  log_every: 10
  use_wandb: false
  wandb_project: codeforge
